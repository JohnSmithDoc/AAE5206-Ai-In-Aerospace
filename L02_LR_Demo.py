import numpy as np # linear algebra
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.animation as animation

def load_data():

    # ç”¨äºç³»ç»Ÿäº¤äº’æ“ä½œ
    import os

    # è·å–å½“å‰å·¥ä½œç›®å½•ï¼ˆCurrent Working Directoryï¼‰
    cwd = os.getcwd()
    print(cwd)

    data = pd.read_csv('./L02_LR_Data/train.csv')

    # åœ°ä¸Šå±…ä½é¢ç§¯
    x = data['GrLivArea']
    # æˆ¿å±‹çš„é”€å”®ä»·æ ¼
    y = data['SalePrice']

    #pre-processing
    # å°† x æ ‡å‡†åŒ–ä¸ºå‡å€¼ä¸º 0ã€æ ‡å‡†å·®ä¸º 1 çš„æ•°æ®
    x = (x - x.mean()) / x.std()   ## Nx1

    # åœ¨æ ‡å‡†åŒ–åçš„xå‰æ·»åŠ ä¸€åˆ—å…¨ä¸º1çš„åˆ—ï¼š
    #   np.ones(x.shape[0])ï¼šç”Ÿæˆä¸€ä¸ªé•¿åº¦ä¸ºNçš„å…¨1æ•°ç»„ã€‚x.shape[0]è·å–xçš„è¡Œæ•°
    #   np.c_[]ï¼šå°†å…¨1æ•°ç»„å’Œæ ‡å‡†åŒ–åçš„xæŒ‰åˆ—æ‹¼æ¥ã€‚ç»“æœæ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸ºNx2 çš„æ•°ç»„ï¼Œ
    #   ç¬¬ä¸€åˆ—å…¨ä¸º1ï¼ˆç”¨äºçº¿æ€§å›å½’ä¸­çš„æˆªè·é¡¹ï¼‰ï¼Œç¬¬äºŒåˆ—æ˜¯æ ‡å‡†åŒ–åçš„xã€‚

    x = np.c_[np.ones(x.shape[0]),x]  ##  Nx2

    return x, y

def gradient_descent(x, y):
    N = y.size  # No. of data points

    learning_rate = 0.01  # Step size
    iterations = 2000  # No. of iterations
    epsilon = 0.0001

    np.random.seed(123)

    # è¿™è¡Œä»£ç ç”Ÿæˆä¸€ä¸ªåŒ…å«ä¸¤ä¸ªéšæœºæ•°çš„ä¸€ç»´æ•°ç»„ï¼ˆå‘é‡ï¼‰ï¼Œè¿™äº›éšæœºæ•°åœ¨ [0, 1) åŒºé—´å†…å‡åŒ€åˆ†å¸ƒã€‚np.random.rand(2) è¿”å›ä¸€ä¸ªå½¢çŠ¶ä¸º (2,) çš„æ•°ç»„
    # æ³¨æ„è¿™é‡Œwåªæœ‰ä¸¤ä¸ªå…ƒç´ å“¦
    w = np.random.rand(2) # step 1
    all_avg_err = []
    all_w = [w]

    for i in range(iterations):
        ## forward pass
        ## è®¡ç®—xå’Œwçš„ç‚¹ç§¯ï¼Œæ³¨æ„è¿™é‡Œå°±æ˜¯æ›²çº¿æ‹Ÿåˆæ—¶æˆ‘ä»¬å‡è®¾æ˜¯çº¿æ€§æ‹Ÿåˆy = wx + bï¼Œè€Œä¸”æ˜¯ä¸¤ä¸ªæœªçŸ¥æ•°ï¼Œæˆ‘ä»¬å°±æ˜¯æ±‚w å’Œ b
        ## ä½†æ˜¯æˆ‘ä»¬å°†xçš„ä¸€åˆ—å…¨éƒ½å˜ä¸ºäº†1,æ­¤æ—¶å°±å¯ä»¥åŒ–ç®€ä¸º y = w^T * xï¼Œæ³¨æ„è¿™é‡Œçš„wæœ‰ä¸¤ä¸ªå…ƒç´ å“¦ï¼Œä¸€ä¸ªæ˜¯w,å¦ä¸€ä¸ªå°±æ˜¯b
        prediction = np.dot(x, w)
        errors = prediction - y
        # åˆ©ç”¨å·²çŸ¥çš„æ•°æ®è®¡ç®—å¹³å‡è¯¯å·®ï¼Œ
        avg_err = 1/N * np.dot(errors.T, errors) # step 2

        # å¦‚æœè¯¯å·®å¾ˆå°ï¼Œåˆ™ç›´æ¥é€€å‡º
        if np.dot(errors.T, errors)< epsilon: break
        all_avg_err.append(avg_err)

        ## æ³¨æ„loss function æ˜¯ 1/ğ‘ * è¯¯å·®çš„å¹³æ–¹å’Œ,
        ## update w     (y^bar -(wT x + b))^2  --> 2(y^bar - (Wt)...)
        ## æ³¨æ„y^baræ˜¯å·²çŸ¥çš„ï¼Œè®¤ä¸ºæ˜¯å¸¸æ•°ï¼Œxä¹Ÿæ˜¯å·²çŸ¥çš„ï¼Œä¹Ÿå¯ä»¥è®¤ä¸ºæ˜¯å¸¸æ•°ï¼Œwæ‰æ˜¯å˜é‡
        ## è¿™é‡Œæ˜¯è¯¯å·®å¯¹wæ±‚å¯¼ï¼Œç„¶ååˆ©ç”¨æ¢¯åº¦ä¸‹é™å“¦ï¼Œ (y^bar - (wT x))^2å¯¹wæ±‚å¯¼å¾— Lâ€˜(w) = 2(y^bar - wTx)* (-xT)
        ## y^bar -wTx = -errorsï¼Œæ‰€ä»¥ L'(w) = -2 * errors * -x^T = 2 * errors * x^T
        ## ç„¶åå› ä¸ºloss functionå®é™…æ˜¯æœ‰1/Nçš„ï¼Œæ‰€ä»¥å˜ä¸º 2/N * errors * x^T
        ## ç„¶ååˆ©ç”¨æ­¤æ—¶çš„æ¢¯åº¦ä¹˜ä»¥æ­¥é•¿ï¼Œæ¥æ›´æ–°wï¼Œè¿™æ ·ä¾¿å¯ä»¥è¿­ä»£è¿›è¡Œæ¢¯åº¦ä¸‹é™
        w = w - learning_rate * (2/N) * np.dot(x.T, errors)
        all_w.append(w)

    return all_w, all_avg_err

def show_err(all_avg_err):
    plt.title('Errors')
    plt.xlabel('No. of iterations')
    plt.ylabel('Err')
    plt.plot(all_avg_err)
    plt.show()

def show_w(x, y, all_w, all_avg_err):
    # Set the plot up,
    fig = plt.figure()
    ax = plt.axes()
    plt.title('Sale Price vs Living Area')
    plt.xlabel('Living Area in square feet (normalised)')
    plt.ylabel('Sale Price ($)')
    plt.scatter(x[:, 1], y, color='red')
    line, = ax.plot([], [], lw=2)

    # åœ¨åæ ‡ä½ç½® (-1, 700000) å¤„åˆ›å»ºä¸€ä¸ªç©ºçš„æ–‡æœ¬æ³¨é‡Šï¼Œåç»­ä¼šåŠ¨æ€å˜åŠ¨è¿™ä¸ªæ³¨é‡Šå†…å®¹
    annotation = ax.text(-1, 700000, '')
    annotation.set_animated(True)
    plt.close()

    def init():
        # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„çº¿
        line.set_data([], [])
        annotation.set_text('')
        return line, annotation

    # animation function.  This is called sequentially
    def animate(i):
        # ä»-5 ~ 20ç”Ÿæˆ 1000ä¸ªx
        x = np.linspace(-5, 20, 1000)
        # åˆ©ç”¨ä¸Šè¿°xè®¡ç®—å¯¹åº”çš„y
        y = all_w[i][1] * x + all_w[i][0]
        # åº”ä¸ºxå’Œyå‡æœ‰å¤šä¸ªå€¼ï¼Œåˆ™å¯ä»¥ç”Ÿæˆä¸€æ¡ç›´çº¿
        line.set_data(x, y)
        annotation.set_text('err = %.2f e10' % (all_avg_err[i] / 10000000000))
        return line, annotation

    anim = animation.FuncAnimation(fig, animate, init_func=init, frames=300, interval=0, blit=True)
    anim.save('animation.gif', writer='imagemagick', fps=30)
    print('animation saved!')




def demo():
    x, y = load_data()

    all_w, all_avg_err = gradient_descent(x, y)

    # æœ€åä¸€ä¸ªwå°±æ˜¯è¿­ä»£å‡ºæ¥çš„æœ€ä¼˜çš„å‚æ•°w1 å’Œ w2ï¼Œ w1å…¶å®æ˜¯b, w2æ˜¯w y = wx + b = W^Tx
    w = all_w[-1]
    print("Estimated w1, w2: {:.2f}, {:.2f}".format(w[0], w[1]))

    # show_err(all_avg_err)
    show_w(x, y, all_w, all_avg_err)

################################
if __name__ == "__main__":
    demo()